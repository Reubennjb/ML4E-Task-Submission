{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1_2xL5WjmfnzkSOWDxc0xd17YXbC2thZo","timestamp":1756299716949}],"toc_visible":true,"authorship_tag":"ABX9TyPW4O0a/iKrvR+gzw7s/haU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eFy_T-_8kwck","executionInfo":{"status":"ok","timestamp":1756299633800,"user_tz":-330,"elapsed":6867,"user":{"displayName":"Reuben Johny","userId":"01700841312521627508"}},"outputId":"8fef4b38-34e4-49d0-8abd-2eb12416c989"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"]}]},{"cell_type":"code","source":["!pip install torchtext"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1cFk_N9RkzFk","executionInfo":{"status":"ok","timestamp":1756299646596,"user_tz":-330,"elapsed":12775,"user":{"displayName":"Reuben Johny","userId":"01700841312521627508"}},"outputId":"e62f4642-d4a7-4726-c69b-d922e8ef39e6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchtext in /usr/local/lib/python3.12/dist-packages (0.18.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.32.4)\n","Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.8.0+cu126)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (4.14.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.4.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2025.8.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.3.0->torchtext) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.2)\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JAxiubCYn45","executionInfo":{"status":"ok","timestamp":1756299647008,"user_tz":-330,"elapsed":410,"user":{"displayName":"Reuben Johny","userId":"01700841312521627508"}},"outputId":"57893ab7-6e7f-4229-dfef-8877c45ca1cd"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Loss: 2.9423\n","Epoch 2 Loss: 2.8638\n","Epoch 3 Loss: 2.8606\n","Epoch 4 Loss: 2.7130\n","Epoch 5 Loss: 2.6898\n","\n","Sample Translation:\n","Hindi: मैं घर जा रहा हूँ\n","English: you rahul\n"]}],"source":["# -------------------------------------------\n","# Hindi → English Translation using Seq2Seq\n","# With PyTorch + NLTK (No HuggingFace)\n","# -------------------------------------------\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","import nltk\n","nltk.download(\"punkt\")\n","\n","# ----------------------------\n","# 1. Load Dataset\n","# ----------------------------\n","with open(\"hindi.txt\", \"r\", encoding=\"utf-8\") as f:\n","    hindi_sentences = f.read().splitlines()\n","\n","with open(\"english.txt\", \"r\", encoding=\"utf-8\") as f:\n","    english_sentences = f.read().splitlines()\n","\n","# ----------------------------\n","# 2. Preprocessing\n","# ----------------------------\n","from nltk.tokenize import word_tokenize\n","\n","def tokenize(sentences, lang=\"english\"):\n","    return [word_tokenize(s.lower()) for s in sentences]\n","\n","hindi_tokens = tokenize(hindi_sentences, lang=\"hindi\")\n","english_tokens = tokenize(english_sentences, lang=\"english\")\n","\n","def build_vocab(tokenized_sentences):\n","    vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n","    idx = 4\n","    for sent in tokenized_sentences:\n","        for word in sent:\n","            if word not in vocab:\n","                vocab[word] = idx\n","                idx += 1\n","    return vocab\n","\n","src_vocab = build_vocab(hindi_tokens)\n","tgt_vocab = build_vocab(english_tokens)\n","\n","inv_tgt_vocab = {v: k for k, v in tgt_vocab.items()}\n","\n","def encode(sentences, vocab):\n","    return [[vocab.get(word, vocab[\"<unk>\"]) for word in sent] + [vocab[\"<eos>\"]] for sent in sentences]\n","\n","src_data = encode(hindi_tokens, src_vocab)\n","tgt_data = encode(english_tokens, tgt_vocab)\n","\n","# ----------------------------\n","# 3. DataLoader with Padding\n","# ----------------------------\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for src, tgt in batch:\n","        src_batch.append(torch.tensor(src, dtype=torch.long))\n","        tgt_batch.append(torch.tensor(tgt, dtype=torch.long))\n","    src_batch = pad_sequence(src_batch, padding_value=src_vocab[\"<pad>\"])\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=tgt_vocab[\"<pad>\"])\n","    return src_batch, tgt_batch\n","\n","pairs = list(zip(src_data, tgt_data))\n","train_loader = DataLoader(pairs, batch_size=32, shuffle=True, collate_fn=collate_fn)\n","\n","# ----------------------------\n","# 4. Seq2Seq Model\n","# ----------------------------\n","class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True)\n","\n","    def forward(self, src):\n","        embedded = self.embedding(src)\n","        outputs, hidden = self.rnn(embedded)\n","        return hidden\n","\n","class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True)\n","        self.fc = nn.Linear(hid_dim, output_dim)\n","\n","    def forward(self, input, hidden):\n","        if input.dim() == 0:\n","            input = input.unsqueeze(0)\n","        input = input.unsqueeze(1)\n","        embedded = self.embedding(input)\n","        output, hidden = self.rnn(embedded, hidden)\n","        prediction = self.fc(output.squeeze(1))\n","        return prediction, hidden\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n","        batch_size = tgt.shape[1]\n","        max_len = tgt.shape[0]\n","        tgt_vocab_size = len(tgt_vocab)\n","\n","        outputs = torch.zeros(max_len, batch_size, tgt_vocab_size).to(self.device)\n","        hidden = self.encoder(src.transpose(0,1))\n","\n","        input = torch.tensor([tgt_vocab[\"<sos>\"]] * batch_size).to(self.device)\n","\n","        for t in range(1, max_len):\n","            output, hidden = self.decoder(input, hidden)\n","            outputs[t] = output\n","            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n","            top1 = output.argmax(1)\n","            input = tgt[t] if teacher_force else top1\n","        return outputs\n","\n","# ----------------------------\n","# 5. Training\n","# ----------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","INPUT_DIM = len(src_vocab)\n","OUTPUT_DIM = len(tgt_vocab)\n","ENC_EMB_DIM = 64\n","DEC_EMB_DIM = 64\n","HID_DIM = 128\n","\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM)\n","model = Seq2Seq(enc, dec, device).to(device)\n","\n","optimizer = optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab[\"<pad>\"])\n","\n","N_EPOCHS = 5\n","\n","for epoch in range(N_EPOCHS):\n","    model.train()\n","    epoch_loss = 0\n","    for src, tgt in train_loader:\n","        src, tgt = src.to(device), tgt.to(device)\n","        optimizer.zero_grad()\n","        output = model(src, tgt)\n","        output_dim = output.shape[-1]\n","        output = output[1:].view(-1, output_dim)\n","        tgt = tgt[1:].view(-1)\n","        loss = criterion(output, tgt)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","    print(f\"Epoch {epoch+1} Loss: {epoch_loss/len(train_loader):.4f}\")\n","\n","# ----------------------------\n","# 6. Simple Translation\n","# ----------------------------\n","def translate(sentence):\n","    model.eval()\n","    tokens = word_tokenize(sentence.lower())\n","    indices = [src_vocab.get(word, src_vocab[\"<unk>\"]) for word in tokens] + [src_vocab[\"<eos>\"]]\n","    src_tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(1).to(device)\n","\n","    hidden = model.encoder(src_tensor.transpose(0,1))\n","    input = torch.tensor([tgt_vocab[\"<sos>\"]]).to(device)\n","\n","    translated = []\n","    for _ in range(20):\n","        output, hidden = model.decoder(input, hidden)\n","        top1 = output.argmax(1).item()\n","        if top1 == tgt_vocab[\"<eos>\"]:\n","            break\n","        translated.append(inv_tgt_vocab[top1])\n","        input = torch.tensor([top1]).to(device)\n","    return \" \".join(translated)\n","\n","print(\"\\nSample Translation:\")\n","print(\"Hindi: मैं घर जा रहा हूँ\")\n","print(\"English:\", translate(\"मैं घर जा रहा हूँ\"))\n"]}]}